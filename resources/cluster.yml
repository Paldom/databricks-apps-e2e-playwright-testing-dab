resources:
  clusters:
    monitoring_cluster:
      # This is the "named cluster" the jobs run on.
      cluster_name: "${var.cluster_name}-${bundle.target}"

      # Single-node cluster is enough for browser-based monitoring.
      num_workers: 0

      spark_version: "${var.spark_version}"
      node_type_id: "${var.node_type_id}"
      driver_node_type_id: "${var.node_type_id}"

      # Custom container with Playwright + Chromium pre-installed.
      # See: https://docs.databricks.com/aws/en/compute/custom-containers
      docker_image:
        url: "${var.docker_image_url}"

      spark_conf:
        spark.databricks.cluster.profile: singleNode
        spark.master: local[*]

      custom_tags:
        ResourceClass: SingleNode

      autotermination_minutes: 30
      enable_elastic_disk: true

      # Keep this simple; adjust for your workspace security requirements.
      data_security_mode: SINGLE_USER
      single_user_name: ${workspace.current_user.userName}
      runtime_engine: STANDARD
